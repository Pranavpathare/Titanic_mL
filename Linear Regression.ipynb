{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).\n",
    "\n",
    "Linear regression is perhaps one of the most well known and well understood algorithms in statistics and machine learning.\n",
    "\n",
    "There are two types of linear regression- Simple and Multiple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/Cost-Function.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/r2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjR2(y,yhat):\n",
    "    SS_Residual = sum((y-yhat)**2)\n",
    "    SS_Total = sum((y-np.mean(y))**2)\n",
    "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "    adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-1-1)\n",
    "    print(\"The value of adjusted R2 is : {}\".format(adjusted_r_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input X should be in the form of a 1d array\n",
    "# X = [a,\n",
    "#      b,\n",
    "#      c]\n",
    "# y and targets must in the format of a one dimensional array of binary values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __loss(self, yhat, y):\n",
    "        return np.square(yhat - y).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        denominator = X.dot(X) - X.mean()*X.sum()\n",
    "        self.m = (X.dot(y) - y.mean()*(X.sum()))/denominator\n",
    "        self.c = (y.mean()*X.dot(X) - X.mean()*X.dot(y))/denominator\n",
    "     \n",
    "        yhat = self.m*X + self.c\n",
    "        \n",
    "        print(\"Total loss is :\",self.__loss(yhat,y))\n",
    "        print()\n",
    "        print(\"Equation of your line is y = {}x + {}\".format(self.m,self.c))\n",
    "        print()\n",
    "        \n",
    "        adjR2(y,yhat)\n",
    "        \n",
    "        plt.scatter(X,y)\n",
    "        plt.plot(X,yhat)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.m*np.float64(X) + self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3,4,5,6])\n",
    "y = np.array([5,7,9,11,13,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slr = SimpleLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss is : 0.0\n",
      "\n",
      "Equation of your line is y = 2.0x + 3.0\n",
      "\n",
      "The value of adjusted R2 is : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Slr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9., 11.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Slr.predict([3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input X should be in the form of a 2d array\n",
    "# The way scikit learn implements it\n",
    "# X = [[a,b],\n",
    "#      [c,d]]\n",
    "# y and targets must in the format of a one dimensional array of binary values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.flag = False\n",
    "    \n",
    "    def __loss(self, yhat, y):\n",
    "        return np.square(yhat - y).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            self.W = np.linalg.solve(np.dot(X.T,X),np.dot(X.T,y))\n",
    "        except np.linalg.LinAlgError:\n",
    "            self.flag = True\n",
    "        if self.flag == True:\n",
    "            print(\"The matrix in singular, You were caught by the dummy variable trap, use gradient descent instead\")\n",
    "        else:\n",
    "                self.W = np.linalg.solve(np.dot(X.T,X),np.dot(X.T,y))\n",
    "                yhat = X.dot(self.W)\n",
    "\n",
    "                print(\"Total loss is :\",self.__loss(yhat,y))\n",
    "                print()\n",
    "                print(\"Weights are: {}\".format(self.W))\n",
    "                print()\n",
    "\n",
    "                adjR2(y,yhat)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.flag == True:\n",
    "            print(\"No Solution\")\n",
    "        else:\n",
    "            return X.dot(self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,4,5],[6,7,8,9,10]]).reshape(2,5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[:,0]+ 2*X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = MultipleLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss is : 0.0\n",
      "\n",
      "Weights are: [1. 2.]\n",
      "\n",
      "The value of adjusted R2 is : 1.0\n"
     ]
    }
   ],
   "source": [
    "mlr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.predict(np.array([[10,20]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.0001, num_iters=100000):\n",
    "        self.lr = lr\n",
    "        self.num_iters = num_iters\n",
    "    \n",
    "    def __add_ones(self, X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((ones, X), axis=1)\n",
    "    \n",
    "    def __loss(self, yhat, y):\n",
    "        return np.square(yhat - y).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X = self.__add_ones(X)\n",
    "        print(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.W = np.random.randn(X.shape[1])\n",
    "        print(self.W)\n",
    "        \n",
    "        for i in range(self.num_iters):\n",
    "            yhat = X.dot(self.W)\n",
    "            delta = yhat - y\n",
    "            self.W = self.W - self.lr*X.T.dot(delta)\n",
    "\n",
    "        print(\"Weights are: {}\".format(self.W))\n",
    "        \n",
    "        yhat = X.dot(self.W)\n",
    "        adjR2(y,yhat)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
